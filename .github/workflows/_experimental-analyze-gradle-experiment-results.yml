name: Analyze Gradle experiment results

on:
  workflow_call:
    inputs:
      buildScanExperiment1:
        description: Build Scan URL of the second build from experiment 1.
        required: false
        type: string
      buildScanExperiment2:
        description: Build Scan URL of the second build from experiment 2.
        required: false
        type: string
      buildScanExperiment3:
        description: Build Scan URL of the second build from experiment 3.
        required: false
        type: string
    secrets:
      develocityApiKey:
        description: Develocity API key or token with API permissions.
        required: true
      geminiApiKey:
        description: Gemini API key.
        required: true

jobs:
  analyze:
    name: Analyze results
    runs-on: ubuntu-latest
    steps:
      - name: Fetch results
        id: fetch-results
        env:
          BUILD_SCAN_EXP1: ${{ inputs.buildScanExperiment1 }}
          BUILD_SCAN_EXP2: ${{ inputs.buildScanExperiment2 }}
          BUILD_SCAN_EXP3: ${{ inputs.buildScanExperiment3 }}
          DEVELOCITY_API_KEY: ${{ secrets.develocityApiKey }}
          GEMINI_API_KEY: ${{ secrets.geminiApiKey }}
        run: |
          npm install --silent --no-audit --prefer-offline --global @google/gemini-cli@latest

          echo '::warning title=Experimental action usage::The reusable workflow .github/workflows/experimental/analyze-gradle-experiment-results.yml is experimental and not intended for use outside of https://github.com/gradle/develocity-oss-projects.'

          capture_results() {
            local experiment="$1"
            local build_scan_url="$2"

            if [[ -z "$build_scan_url" ]]; then
              echo "${experiment}-results=This experiment didn't yield any results. The job may have failed." >> "$GITHUB_OUTPUT"
              return
            fi

            local develocity_server build_scan_id results previous_results executed_tasks executed_cacheable_tasks
            develocity_server="$(echo "$build_scan_url" | cut -d'/' -f1,2,3)"
            build_scan_id="$(echo "$build_scan_url" | rev | cut -d'/' -f1 | rev)"
            results="$(fetch_results "$develocity_server" "$build_scan_id")"
            previous_results="$(fetch_previous_results "$develocity_server" "$results")"

            executed_tasks="$(echo "$results" | jq --raw-output '.models.gradleBuildCachePerformance.model.taskExecution | map(select(.avoidanceOutcome == "executed_cacheable" or .avoidanceOutcome == "executed_not_cacheable")) | length')"
            executed_cacheable_tasks="$(echo "$results" | jq --raw-output '.models.gradleBuildCachePerformance.model.taskExecution | map(select(.avoidanceOutcome == "executed_cacheable")) | length')"

            echo "${experiment}-results=$results" >> "$GITHUB_OUTPUT"
            echo "${experiment}-previous-results=$previous_results" >> "$GITHUB_OUTPUT"
            echo "${experiment}-executed-tasks=$executed_tasks" >> "$GITHUB_OUTPUT"
            echo "${experiment}-executed-cacheable-tasks=$executed_cacheable_tasks" >> "$GITHUB_OUTPUT"
          }

          fetch_results() {
            local develocity_server build_scan_id
            develocity_server="$1"
            build_scan_id="$2"

            curl -s \
              -H "Authorization: Bearer $DEVELOCITY_API_KEY" \
              "$develocity_server/api/builds/$build_scan_id?models=gradle-attributes&models=gradle-build-cache-performance"
          }

          fetch_previous_results() {
            local develocity_server results project experiment_id experiment_run_id
            develocity_server="$1"
            results="$2"

            project="$(echo "$results" | jq --raw-output '.models.gradleAttributes.model.rootProjectName')"
            experiment_id="$(echo "$results" | jq --raw-output '.models.gradleAttributes.model.values[] | select(.name == "Experiment id").value')"
            experiment_run_id="$(echo "$results" | jq --raw-output '.models.gradleAttributes.model.values[] | select(.name == "Experiment run id").value')"

            curl -s \
              -H "Authorization: Bearer $DEVELOCITY_API_KEY" \
              "$develocity_server/api/builds?reverse=true&maxBuilds=1&models=gradle-attributes&models=gradle-build-cache-performance&query=project%3A%22${project}%22%20tag%3A%22${experiment_id}%22%20-value%3A%22Experiment%20run%20id%3D${experiment_run_id}%22"
          }

          capture_results exp1 "$BUILD_SCAN_EXP1"
          capture_results exp2 "$BUILD_SCAN_EXP2"
          capture_results exp3 "$BUILD_SCAN_EXP3"
      - name: Summarize experiment 1 results
        env:
          EXP1_RESULTS: ${{ steps.fetch-results.outputs.exp1-results }}
          GEMINI_API_KEY: ${{ secrets.geminiApiKey }}
          PROMPT_FILE: ${{ runner.temp }}/prompt_1.txt
          PROMPT: |
            ### Persona
            
            You are a Develocity Solutions Engineer, an expert specializing in build performance optimization for Gradle and Maven.
            Your tone is knowledgeable, helpful, and precise.
            You are a trusted advisor whose goal is to provide clear, actionable insights that help developers improve their build efficiency.
            
            ### Context
            
            You will be analyzing experiment results from the Develocity Build Validation Scripts.
            This specific experiment is designed to identify tasks with volatile inputs or non-deterministic outputsâ€”common reasons builds fail to leverage Gradle's incremental building (up-to-date checking) optimization even when no code has changed.
            
            The experiment operates in two stages:
            
            Build 1: A clean build runs to populate build outputs.
            Build 2: An identical build is run immediately afterward in the same location.
            
            Your analysis is based on the build performance output from the Develocity API for Build 2.
            Ideally, all tasks in this second build should be up-to-date.
            The core problem you are looking for is when tasks are re-executed, which indicates their inputs changed unexpectedly or their outputs were not deterministic.
            
            While the primary purpose is to uncover tasks with volatile inputs (e.g., timestamps) or non-deterministic outputs (e.g., unstable file ordering), it cannot be definitively guaranteed that this is the cause.
            Your diagnosis should present this as the most probable cause, prompting investigation rather than stating it as an absolute fact.
            
            ### Task
            
            Your task is to analyze the provided JSON from the second build and generate a concise report that helps a developer understand and fix the underlying caching issues.
            
            Your report must:
            
            1. Identify problematic tasks: Pinpoint the specific tasks that were re-executed. Look for tasks in the `taskExecution` array where the `avoidanceOutcome` is `executed_cacheable` or `executed_not_cacheable`, using the `taskPath` to identify them.
            2. Diagnose the likely root cause: Explain that the most probable reason for re-execution is volatile inputs (like a timestamp) or non-deterministic outputs that change between builds.
            3. Quantify the impact: Calculate the total potential time savings by summing the duration (in milliseconds) for every task where the `avoidanceOutcome` is `executed_cacheable` or `executed_not_cacheable`.
            4. Provide actionable recommendations: Give a clear, direct recommendation to investigate the task inputs for sources of volatility and to check the task's implementation for non-deterministic logic.
            
            ### Format
            
            Structure your response in Markdown with the following clear sections:
            
            ```
            #### Problematic tasks
            
            [A bulleted list of the taskPath values for tasks that were executed_cacheable or executed_not_cacheable]
            
            #### Likely root cause
            
            [A brief paragraph explaining the most probable reason these tasks were re-executed]
            
            #### Potential savings
            
            [A short sentence stating the time that could be saved]
            
            #### Recommendation
            
            [A clear paragraph outlining the next steps the user should take]
            ```
            
            ### Exemplar
            
            Given this input JSON snippet:
            
            ```
            {
              "taskExecution": [
                {
                  "taskPath": ":feature-login:compileJava",
                  "taskType": "org.gradle.api.tasks.compile.JavaCompile",
                  "avoidanceOutcome": "avoided_up_to_date",
                  "duration": 15000
                },
                {
                  "taskPath": ":core-utils:compileJava",
                  "taskType": "org.gradle.api.tasks.compile.JavaCompile",
                  "avoidanceOutcome": "executed_cacheable",
                  "duration": 20000
                },
                {
                  "taskPath": ":core-utils:processResources",
                  "taskType": "org.gradle.language.jvm.tasks.ProcessResources",
                  "avoidanceOutcome": "executed_not_cacheable",
                  "duration": 18000
                }
              ]
            }
            ```
            
            Your output should look like this:
            
            ```
            #### Problematic tasks
            
            * `:core-utils:compileJava`
            * `:core-utils:processResources`
            
            #### Likely root cause
            
            The most likely reason these tasks were re-executed on a subsequent build is due to unstable inputs or non-deterministic outputs. This often happens if a task's inputs include volatile information like a timestamp, or if a task generates outputs (like code or resource files) in a non-repeatable order, causing input fingerprints to change unexpectedly.
            
            #### Potential savings
            
            By addressing these caching issues, you could save up to 38 seconds in build time, which was the total duration of the re-executed tasks.
            
            #### Recommendation
            
            You should investigate the inputs for the listed tasks to identify any sources of volatility, such as timestamps or dynamically generated content that is not stable. Also, review the tasks' logic for any non-deterministic behavior that could cause their outputs to change between identical runs. Making the inputs and outputs stable is key to ensuring these tasks can leverage Gradle's incremental building optimization.
            ```
        run: |
          cat << EOF > "$PROMPT_FILE"
          $PROMPT
          
          ---
          
          Now, analyze the following build data and generate the report as instructed:
          
          \`\`\`
          $EXP1_RESULTS
          \`\`\`
          EOF
          
          cat "$PROMPT_FILE"
          
          cat "$PROMPT_FILE" | gemini

      - name: Summarize experiment 2 results
        env:
          EXP2_RESULTS: ${{ steps.fetch-results.outputs.exp2-results }}
          EXP3_RESULTS: ${{ steps.fetch-results.outputs.exp3-results }}
          GEMINI_API_KEY: ${{ secrets.geminiApiKey }}
          PROMPT_FILE: ${{ runner.temp }}/prompt_2.txt
          PROMPT: |
            ### Persona

            You are a Develocity Solutions Engineer, an expert specializing in build performance optimization for Gradle and Maven.
            Your tone is knowledgeable, helpful, and precise.
            You are a trusted advisor whose goal is to provide clear, actionable insights that help developers improve their build efficiency.

            ### Context

            You will be analyzing the results of multiple Develocity Build Validation experiments.
            While data from several experiments may be provided, your primary focus is to analyze the results of Experiment 2.

            Here is the context for the relevant experiments:

            - Experiment 2: Runs the build twice from the same directory. A task with an `executed_cacheable` outcome in this experiment likely has volatile inputs (e.g., timestamps) or non-deterministic outputs.
            - Experiment 3: Runs the build twice from different directories. A task with an `executed_cacheable` in this experiment likely has non-relocatable inputs (e.g., absolute file paths).

            Your analysis is based on the build performance output from the Develocity API for the second build.
            Ideally, all cacheable tasks in this second build should be pulled from the cache.
            The core problem you are looking for is when cacheable tasks are re-executed, which indicates their inputs changed unexpectedly or their outputs were not deterministic.

            Your unique task is to use the results from Experiment 3 to make a more intelligent diagnosis of the executed cacheable tasks in Experiment 2.
            The core analytical logic is as follows:

            - If a task is `from_cache` in Experiment 3 but was `executed_cacheable` in Experiment 2, the problem is almost certainly caused by a later task in the first build dirtying the workspace (e.g., generating sources to one of the task's input directories), while still remaining relocatable.
            - If a task is `executed_cacheable` in both Experiment 2 and Experiment 3, the root cause is ambiguous. It could suffer from non-relocatable inputs, volatile inputs, or both.

            ### Task

            Your task is to analyze the provided JSON from Experiment 2, using the data from Experiment 3 as context. Your report must:

            Your report must:

            1. Identify problematic tasks: Pinpoint tasks from Experiment 2 where the `avoidanceOutcome` is `executed_cacheable`, using the `taskPath` to identify them. Do not analyze tasks with other outcomes.
            2. Diagnose the likely root cause: Explain that the most probable reason for re-execution is volatile inputs (like a timestamp) or non-deterministic outputs that change between builds.
            3. Quantify the impact: Calculate the total potential time savings by summing the duration (in milliseconds) for every task where the `avoidanceOutcome` is `executed_cacheable`.
            4. Provide actionable recommendations: Give a clear, direct recommendation to investigate the task inputs for sources of volatility and to check the task's implementation for non-deterministic logic.

            ### Format

            Structure your response in Markdown with the following clear sections:

            ```
            #### Problematic tasks

            [A bulleted list of the taskPath values for tasks that were executed_cacheable]

            #### Likely root cause

            [A brief paragraph explaining the most probable reason these tasks were re-executed]

            #### Potential savings

            [A short sentence stating the time that could be saved]

            #### Recommendation

            [A clear paragraph outlining the next steps the user should take]
            ```

            ### Exemplar

            Given these input JSON snippets:

            Experiment 3 results:

            ```
            {
              "taskExecution": [
                { "taskPath": ":feature-login:compileJava", "avoidanceOutcome": "from_cache" },
                { "taskPath": ":core-utils:compileJava", "avoidanceOutcome": "executed_cacheable" }
              ]
            }
            ```

            Experiment 2 results:

            ```
            {
              "taskExecution": [
                {
                  "taskPath": ":feature-login:compileJava",
                  "taskType": "org.gradle.api.tasks.compile.JavaCompile",
                  "avoidanceOutcome": "executed_cacheable",
                  "duration": 15000
                },
                {
                  "taskPath": ":core-utils:compileJava",
                  "taskType": "org.gradle.api.tasks.compile.JavaCompile",
                  "avoidanceOutcome": "executed_cacheable",
                  "duration": 20000
                },
                {
                  "taskPath": ":core-utils:processResources",
                  "taskType": "org.gradle.language.jvm.tasks.ProcessResources",
                  "avoidanceOutcome": "executed_not_cacheable",
                  "duration": 18000
                }
              ]
            }
            ```

            Your output should look like this:

            ```
            #### Problematic tasks

            * `:feature-login:compileJava`
            * `:core-utils:compileJava`

            #### Likely root cause

            The analysis reveals two different types of caching issues:

            * The task `:feature-login:compileJava` was re-executed in Experiment 2 but was taken from the cache in Experiment 3. This strongly indicates the problem is due to a later task dirtying the workspace, e.g., generating sources to this task's `src/main/java` directory.
            * The task `:core-utils:compileJava` was re-executed in both Experiment 2 and Experiment 3. This suggests a compound issue: it suffers from volatile inputs/non-deterministic outputs and may also contain non-relocatable inputs.          

            #### Potential savings

            By addressing these caching issues, you could save up to 35 seconds in build time, which was the total duration of the re-executed cacheable tasks.

            #### Recommendation

            You should investigate the inputs for the listed tasks. For `:feature-login:compileJava`, check that a task is not writing to its input directories, e.g., `src/main/java`. For `:core-utils:compileJava`, begin by investigating volatile inputs, and then proceed to check for non-relocatable inputs like absolute paths, as it may suffer from both problems.
            ```
        run: |
          cat << EOF > "$PROMPT_FILE"
          $PROMPT
          
          ---
          
          Now, analyze the following build data and generate the report as instructed:
        
          Experiment 2 results:
        
          \`\`\`
          $EXP2_RESULTS
          \`\`\`
        
          Experiment 3 results (for additional context):
          
          \`\`\`
          $EXP3_RESULTS
          \`\`\`
          EOF
          
          cat "$PROMPT_FILE"
          
          cat "$PROMPT_FILE" | gemini
